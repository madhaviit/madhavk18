<!doctype html><!-- This site was created with Wowchemy. https://www.wowchemy.com --><!-- Last Published: March 14, 2023 --><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.7.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><link rel=stylesheet href=/css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.0f229d4b7ebad1917a9a357cba2effab.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=author content="Madhav Kadam"><meta name=description content="How my team representing IIT Indore bagged an absolute Gold Medal in Inter IIT Tech Meet 11.0 (2023 edition at IIT Kanpur) for the Mid-Prep &ldquo;The Vital Extraction&rdquo; Challenge by Cloudphysician."><link rel=alternate hreflang=en-us href=https://madhaviit.github.io/post/the-vital-extraction-challenge/><link rel=canonical href=https://madhaviit.github.io/post/the-vital-extraction-challenge/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#1565c0"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:site" content="@wowchemy"><meta property="twitter:creator" content="@wowchemy"><meta property="twitter:image" content="https://madhaviit.github.io/post/the-vital-extraction-challenge/featured.png"><meta property="og:site_name" content="Academic"><meta property="og:url" content="https://madhaviit.github.io/post/the-vital-extraction-challenge/"><meta property="og:title" content="The Vital Extraction Challenge | Academic"><meta property="og:description" content="How my team representing IIT Indore bagged an absolute Gold Medal in Inter IIT Tech Meet 11.0 (2023 edition at IIT Kanpur) for the Mid-Prep &ldquo;The Vital Extraction&rdquo; Challenge by Cloudphysician."><meta property="og:image" content="https://madhaviit.github.io/post/the-vital-extraction-challenge/featured.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2023-03-13T10:39:21+00:00"><meta property="article:modified_time" content="2023-03-13T10:39:21+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://madhaviit.github.io/post/the-vital-extraction-challenge/"},"headline":"The Vital Extraction Challenge","image":["https://madhaviit.github.io/post/the-vital-extraction-challenge/featured.png"],"datePublished":"2023-03-13T10:39:21Z","dateModified":"2023-03-13T10:39:21Z","author":{"@type":"Person","name":"Madhav Kadam"},"publisher":{"@type":"Organization","name":"Academic","logo":{"@type":"ImageObject","url":"https://madhaviit.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_3.png"}},"description":"How my team representing IIT Indore bagged an absolute Gold Medal in Inter IIT Tech Meet 11.0 (2023 edition at IIT Kanpur) for the Mid-Prep \u0026ldquo;The Vital Extraction\u0026rdquo; Challenge by Cloudphysician."}</script><title>The Vital Extraction Challenge | Academic</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=db0db33a43a494b5d94071a84032f348><script src=/js/wowchemy-init.min.ec9d49ca50e4b80bdb08f0417a28ed84.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Academic</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Academic</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#posts><span>Posts</span></a></li><li class=nav-item><a class=nav-link href=/#projects><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/#talks><span>Talks</span></a></li><li class=nav-item><a class=nav-link href=/#featured><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#contact><span>Contact</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class="nav-item d-none d-lg-inline-flex"><a class=nav-link href=https://twitter.com/mkiitind data-toggle=tooltip data-placement=bottom title="Follow me on Twitter" target=_blank rel=noopener aria-label="Follow me on Twitter"><i class="fab fa-twitter" aria-hidden=true></i></a></li><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><article class=article><div class="article-container pt-3"><h1>The Vital Extraction Challenge</h1><p class=page-subtitle>How my team representing IIT Indore bagged an absolute Gold Medal in Inter IIT Tech Meet 11.0 (2023 edition at IIT Kanpur) for the Mid-Prep &ldquo;The Vital Extraction&rdquo; Challenge by Cloudphysician.</p><div class=article-metadata><span class=article-date>Mar 13, 2023</span>
<span class=middot-divider></span>
<span class=article-reading-time>6 min read</span></div></div><div class="article-header article-container featured-image-wrapper mt-4 mb-4" style=max-width:720px;max-height:516px><div style=position:relative><img src=/post/the-vital-extraction-challenge/featured_hue4444ab39c917427a2c0c5101d9f7ead_9843344_720x2500_fit_q75_h2_lanczos_3.webp width=720 height=516 alt class=featured-image></div></div><div class=article-container><div class=article-style><h1 id=how-my-team-representing-iit-indore-bagged-an-absolute-gold-medal-in-inter-iit-tech-meet-110-2023-edition-at-iit-kanpur-for-the-mid-prep-the-vital-extraction-challenge-by-cloudphysician>How my team representing IIT Indore bagged an absolute Gold Medal in Inter IIT Tech Meet 11.0 (2023 edition at IIT Kanpur) for the Mid-Prep &ldquo;The Vital Extraction&rdquo; Challenge by Cloudphysician.</h1><h2 id=abstract>Abstract:</h2><p>The vital extraction challenge aims to extract a patient&rsquo;s vitals from the image of an ICU monitor. Monitoring vitals is critical to providing high-quality care to patients and is essential for ensuring the best possible patient outcomes. While current guidelines state that the nurse-to-patient ratio should be 1:6, various practical issues result in a much worse scenario. This is why it is important to find newer and more efficient solutions to help solve this problem.</p><p>While it would be preferable to skip the camera-based monitoring system and directly feed the vitals into a common server, we recognize the fact that this solution is not an efficient solution for ICUs around India that are already up and running. There is a need to augment the existing ICU environments in order to capture the necessary vitals from an “offline” patient monitor and feed it into an “online” server for monitoring.</p><p>Precisely, this is the task assigned to us. This challenge required the development of a pipeline to first detect and segment the monitor&rsquo;s screen from the image and then detect, segment, and understand the various vitals present on the screen.</p><h2 id=pipeline>Pipeline</h2><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=https://user-images.githubusercontent.com/122287288/217323177-4d3aa8bd-5954-4043-aba3-a0a33584d34a.png alt="Pipeline_fin drawio (1)" loading=lazy data-zoomable></div></div></figure></p><p>We propose to solve the task with a 3-step solution, namely, Preprocessing, Vital Detection, and OCR. Lastly, we also tackled the HR Graph digitization.</p><h3 id=preprocessing>Preprocessing</h3><p>First, there is the segmentation of the monitor screen and separating it from the surroundings. Secondly, we have to scale the segmented screen to a uniform size for later stages while preserving the original resolution as much as possible. We apply the perspective transformation on the segmented image to obtain the resultant image.</p><h3 id=vital-detection>Vital Detection</h3><p>This stage in the pipeline aims to detect the appropriate vitals in the cropped and transformed monitor screen. However, there was a lot of unlabelled data, and manually annotating all 9000 images was not an option. And it will never be a good solution in any real-world scenario. We identified two methods to deal with the vast amount of unlabelled data.</p><p>One approach was to use a customized Semi-Supervised Learning Model, which would learn from the small amount of labelled data and use it to generate pseudo labels and then true labels for the unlabelled data.</p><p>Another approach was to intelligently pick and manually annotate a small amount of unlabelled data and then add it to the training dataset in order to bring maximum diversity and representation to the training data without much effort. This approach was chosen because of its better results and lesser computational requirement.</p><h3 id=ocr>OCR</h3><p>Finally, we applied an OCR to extract the values of the vitals. This was not a particularly difficult task considering the standardized fonts used on patient monitors. However, there were a few misreads in the final result, such as “0” being read as “o” or “O”, “1” being read as “I”, etc. Due to some detection inaccuracies, we would also see brackets creep into the detection box. Due to segmentation faults, sometimes the numbers at the left corner of the screen, most usually the Systolic pressure in monitors which display it at the bottom left, lose the hundreds’ place digit. We fix such issues by hard-coding a few logic-based checks and corrections to get the most logical possibility for the correct value.</p><h3 id=hr-graph-digitization>HR Graph Digitization</h3><p>Initially, we converted the HR graph segmented image into binary. In order to selectively obtain only the graph, the longest connected pixels row-wise were saved, and the rest discarded. The 2-D binary image was then projected into a 1-D Time Series. The plot was further rescaled in the x and y variables.</p><h2 id=models-used>Models Used:</h2><p>Segmentation: We use the YOLO v8-n model for segmentation of monitor screens from input image. It gave 0.995 mAP50 and 0.987 mAP50-95 with inference time of around 120 ms.</p><p>Preprocessing: The segmented image is then approximated into a quadrilateral (four points). We apply perspective transformation which brings vitals to more readable form.</p><p>Vital Detection: We use YOLO v8-s model for vital extraction from preprocessed image. It gave 0.988 mAP50 and 0.849 mAP50-95 with inference time of around 200 ms.</p><p>OCR of vitals: We use Paddle OCR because of its accuracy and speed.</p><h3 id=segmentation-model-metrics>Segmentation model metrics:</h3><table><thead><tr><th>Model</th><th>Epochs</th><th>Box Precision</th><th>Box Recall</th><th>mAP50</th><th>mAP50-95</th></tr></thead><tbody><tr><td>YOLOv8n</td><td>30</td><td>1</td><td>1</td><td>0.995</td><td>0.987</td></tr><tr><td>YOLOv8s</td><td>85</td><td>1</td><td>1</td><td>0.995</td><td>0.987</td></tr><tr><td>Mask RCNN</td><td>250</td><td></td><td></td><td>0.99</td><td>0.918</td></tr></tbody></table><table><thead><tr><th>Model</th><th>Epochs</th><th>IOU Loss</th><th>Mean Accuracy</th><th>Mean IOU</th></tr></thead><tbody><tr><td>Segformer</td><td>35</td><td>0.011</td><td>0.992</td><td>0.985</td></tr></tbody></table><h3 id=detection-model-metrics>Detection model metrics:</h3><table><thead><tr><th>Model</th><th>Epochs</th><th>Box Precision</th><th>Box Recall</th><th>mAP50</th><th>mAP50-95</th></tr></thead><tbody><tr><td>YOLOv8n</td><td>25</td><td>0.986</td><td>0.993</td><td>0.99</td><td>0.831</td></tr><tr><td>YOLOv8s</td><td>100</td><td>0.983</td><td>0.989</td><td>0.988</td><td>0.849</td></tr><tr><td>YOLOv8m</td><td>100</td><td>0.981</td><td>0.988</td><td>0.989</td><td>0.841</td></tr><tr><td>YOLOv7 (R)</td><td></td><td>0.991</td><td>0.996</td><td>0.993</td><td>0.83</td></tr><tr><td>YOLOv6</td><td>200</td><td></td><td></td><td>0.954</td><td>0.721</td></tr><tr><td>DETR</td><td>45</td><td></td><td></td><td>0.979</td><td>0.688</td></tr><tr><td>RetinaNet</td><td>20</td><td></td><td></td><td>0.595</td><td>0.286</td></tr></tbody></table><h3 id=optical-character-recognition>Optical Character Recognition</h3><table><thead><tr><th>Model</th><th>Accuracy</th><th>Dataset</th><th>Inference Time</th></tr></thead><tbody><tr><td>PaddleOCR</td><td>74.80</td><td>ICDAR15</td><td>8.54ms (per image)</td></tr></tbody></table><h2 id=some-other-novel-techniques-we-have-tried>Some other novel techniques we have tried:</h2><h2 id=applying-image-processing-to-extract-monitor-screen>Applying Image processing to extract monitor screen</h2><p>We can use the fact that the monitor is often of low saturation and is low in red and green channels to apply the filter.</p><p>This follows the use of the brown colour filter followed by a grey colour filter which would encompass most things in the foreground (white monitor boundaries and gray-ish and brown-ish walls and other items)
The problem with this approach, however, is that this generates a bounding box that would contain a tilted monitor screen for certain images. The tilted perspective caused a loss of accuracy which was not a favorable trade-off.</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=https://user-images.githubusercontent.com/122287288/217328716-84db5210-7af1-450a-be77-16020414ee41.jpeg alt="WhatsApp Image 2023-02-07 at 23 32 42" loading=lazy data-zoomable></div></div></figure></p><h2 id=applying-object-detection-for-corners-on-semantic-segmentation>Applying object detection for corners on semantic segmentation</h2><p>We exploit the fact that the monitors will always be a quadrilateral to train the model on two bounding boxes, one for each of the two opposite corner points, converting the problem from semantic segmentation to object detection problem. This results in the increase in speed of our model, however, it fails in particular use cases where it is unable to detect one of the objects due to overlap problems in particular niche use-cases. Since accuracy is the priority we opt for segmentation for a minimal time trade-off.</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=https://user-images.githubusercontent.com/122287288/217328932-df292937-9954-4359-93f0-1ee30de3e36d.jpeg alt="WhatsApp Image 2023-02-07 at 23 32 50" loading=lazy data-zoomable></div></div></figure></p><h2 id=additional-annotation>Additional Annotation</h2><p>We added around 800 labelled images with the help of the SCAN algorithm. SCAN (Semantic Clustering by Adopting Nearest-neighbour) is an unsupervised learning technique for image clustering.</p><p>We first made an embedding of images by training an encoder. After that, we found the nearest neighbour of each image and trained a model to find the clusters in the embedding. Finally, we took some images from each of the clusters and added them to our training dataset for better training.</p><h2 id=semi-supervised-learning>Semi-supervised Learning:</h2><p>Semi-supervised learning is an efficient way to label unlabeled data. We first train an object detection model using available labelled data in this approach. Then, we make a copy of the trained model. One model is defined as the teacher model and the other one as the student. We pick a batch of unlabeled data and let the teacher model make predictions on this data. Now, the confident predictions (confidence value above a certain threshold) among these are assigned as Pseudo Labels. The student model is trained using an augmented version of these confident images and pseudo labels set as the target labels. The student model is allowed to train for 10 epochs. After 10 epochs, the weights of the teacher model are updated by the student model by Exponential Moving Average (EMA), and the process repeats. This way, the available unlabeled data is used to improve the model, which was already trained on available labelled data.</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=https://user-images.githubusercontent.com/122287288/217329013-482772e5-eb84-4c75-bac3-116c6434e1e5.png alt="SSL_fin drawio (1)" loading=lazy data-zoomable></div></div></figure></p></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fmadhaviit.github.io%2Fpost%2Fthe-vital-extraction-challenge%2F&amp;text=The+Vital+Extraction+Challenge" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Fmadhaviit.github.io%2Fpost%2Fthe-vital-extraction-challenge%2F&amp;t=The+Vital+Extraction+Challenge" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=The%20Vital%20Extraction%20Challenge&amp;body=https%3A%2F%2Fmadhaviit.github.io%2Fpost%2Fthe-vital-extraction-challenge%2F" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fmadhaviit.github.io%2Fpost%2Fthe-vital-extraction-challenge%2F&amp;title=The+Vital+Extraction+Challenge" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=The+Vital+Extraction+Challenge%20https%3A%2F%2Fmadhaviit.github.io%2Fpost%2Fthe-vital-extraction-challenge%2F" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=https%3A%2F%2Fmadhaviit.github.io%2Fpost%2Fthe-vital-extraction-challenge%2F&amp;title=The+Vital+Extraction+Challenge" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo><i class="fab fa-weibo"></i></a></li></ul></div><div class="media author-card content-widget-hr"><a href=https://madhaviit.github.io><img class="avatar mr-3 avatar-circle" src=/authors/admin/avatar_hu7601307bef2afcede6c0b762314fae36_240613_270x270_fill_lanczos_center_3.png alt="Madhav Kadam"></a><div class=media-body><h5 class=card-title><a href=https://madhaviit.github.io>Madhav Kadam</a></h5><h6 class=card-subtitle>Computer Science Undergrad @IITI</h6><p class=card-text>I am wildly interested in research in Data Science and its applications.</p><ul class=network-icon aria-hidden=true><li><a href=/#contact><i class="fas fa-envelope"></i></a></li><li><a href=https://twitter.com/mkiitind target=_blank rel=noopener><i class="fab fa-twitter"></i></a></li><li><a href="https://scholar.google.co.uk/citations?user=sIwtMXoAAAAJ" target=_blank rel=noopener><i class="fas fa-graduation-cap"></i></a></li><li><a href=https://github.com/madhaviit target=_blank rel=noopener><i class="fab fa-github"></i></a></li><li><a href=https://www.linkedin.com/in/madhav-kadam/ target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a href=/uploads/resume.pdf><i class="ai ai-cv"></i></a></li></ul></div></div></div></article></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">© 2023 Me. This work is licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND 4.0</a></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.d26509351aa0ff874abbee824e982e9b.js></script>
<script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script>
<script src=/en/js/wowchemy.min.e8ee06ba8371980ffde659871dd593b0.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script></body></html>